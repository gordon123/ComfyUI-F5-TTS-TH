import os
import sys
import tempfile
import torch
import torchaudio
import soundfile as sf
from omegaconf import OmegaConf
import comfy
from .Install import Install
from huggingface_hub import HfApi, hf_hub_url
import requests
from tqdm.auto import tqdm

# Ensure the submodule is initialized
Install.check_install()

# ----- Import English-to-Thai transliteration (local file) -----
from .ARPABET2ThaiScript import eng_to_thai_translit

# ----- Add F5-TTS source path for imports -----
f5tts_src = os.path.join(Install.base_path, "src")
sys.path.insert(0, f5tts_src)

# Main inference imports
from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    load_model,
    load_vocoder,
    preprocess_ref_audio_text,
    infer_process,
    remove_silence_for_generated_wav,
)
from f5_tts.cleantext.number_tha import replace_numbers_with_thai
from f5_tts.cleantext.th_repeat import process_thai_repeat

# Clean up path
sys.path.pop(0)


def download_with_progress(url: str, local_path: str):
    """
    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å URL ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏™‡∏î‡∏á progress bar ‡∏î‡πâ‡∏ß‡∏¢ tqdm
    """
    response = requests.get(url, stream=True)
    response.raise_for_status()
    total_bytes = int(response.headers.get("content-length", 0))
    chunk_size = 8192

    with tqdm(
        total=total_bytes,
        unit="iB",
        unit_scale=True,
        desc=os.path.basename(local_path),
        leave=False,
    ) as t:
        with open(local_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    f.write(chunk)
                    t.update(len(chunk))


class F5TTS_Advance:
    """
    ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ:
    1. ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå .pt ‡∏à‡∏≤‡∏Å‡∏£‡∏µ‡πÇ‡∏õ VIZINTZOR/F5-TTS-THAI ‡πÅ‡∏•‡∏∞ Muscari/F5-TTS-TH_Finetuned
    2. ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏û‡∏¥‡∏°‡∏û‡πå <repo_id>/model/<filename>.pt ‡∏´‡∏£‡∏∑‡∏≠ <repo_id>/<filename>.pt ‡πÑ‡∏î‡πâ‡πÄ‡∏≠‡∏á
    3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå model/ ‡∏Å‡πá‡∏à‡∏∞‡∏•‡∏≠‡∏á fallback ‡πÑ‡∏õ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å root ‡∏Ç‡∏≠‡∏á‡∏£‡∏µ‡πÇ‡∏õ
    """

    # ‡∏£‡∏µ‡πÇ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏ù‡πâ‡∏≤‡∏°‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå .pt ‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå model/
    WATCHED_REPOS = [
        "VIZINTZOR/F5-TTS-THAI",
        "Muscari/F5-TTS-TH_Finetuned",
    ]

    @classmethod
    def INPUT_TYPES(cls):
        api = HfApi()
        model_suggestions = []

        # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå .pt ‡∏à‡∏≤‡∏Å "model/" ‡∏ó‡∏∏‡∏Å‡∏£‡∏µ‡πÇ‡∏õ‡πÉ‡∏ô WATCHED_REPOS
        for repo in cls.WATCHED_REPOS:
            try:
                files = api.list_repo_files(repo_id=repo)
            except Exception:
                continue

            for fn in files:
                if fn.startswith("model/") and fn.endswith(".pt"):
                    model_suggestions.append(f"{repo}/{fn}")

        model_suggestions = sorted(model_suggestions)
        default_choice = model_suggestions[-1] if model_suggestions else ""

        description_text = (
            "‡∏û‡∏¥‡∏°‡∏û‡πå <namespace>/<repo_name>/model/<filename>.pt ‡∏´‡∏£‡∏∑‡∏≠\n"
            "<namespace>/<repo_name>/<filename>.pt\n"
            "‡πÄ‡∏ä‡πà‡∏ô VIZINTZOR/F5-TTS-THAI/model/model_650000_FP16.pt\n"
            "‡∏´‡∏£‡∏∑‡∏≠ Muscari/F5-TTS-TH_Finetuned/model_62400.pt\n\n"
        )
        if model_suggestions:
            description_text += "‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á:\n" + "\n".join(model_suggestions)

        return {
            "required": {
                "sample_audio": ("AUDIO",),
                "sample_text": ("STRING", {"default": "Text of sample_audio"}),
                "text": ("STRING", {"multiline": True, "default": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"}),
                # model_path: ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á <repo>/model/<file>.pt ‡∏´‡∏£‡∏∑‡∏≠ <repo>/<file>.pt
                "model_path": ("STRING", {
                    "default": default_choice,
                    "description": description_text
                }),
                "seed": ("INT", {"default": -1, "min": -1}),
            },
            "optional": {
                "remove_silence": ("BOOL", {"default": True}),
                "speed": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 5.0, "step": 0.1}),
                "cross_fade_duration": ("FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01}),
                "nfe_step": ("INT", {"default": 32, "min": 1, "max": 128}),
                "cfg_strength": ("FLOAT", {"default": 2.0, "min": 0.0, "max": 10.0, "step": 0.1}),
                "sway_sampling_coef": ("FLOAT", {"default": -1.0, "min": -5.0, "max": 5.0, "step": 0.1}),
                "fix_duration": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 30.0, "step": 0.1}),
                "max_chars": ("INT", {"default": 250, "min": 1, "max": 2000}),
            },
        }

    RETURN_TYPES = ("AUDIO", "STRING")
    RETURN_NAMES = ("audio", "text")
    FUNCTION = "synthesize"
    CATEGORY = "üáπüá≠ Thai TTS"

    def synthesize(
        self,
        sample_audio,
        sample_text,
        text,
        model_path="",        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö <repo_id>/model/<filename>.pt ‡∏´‡∏£‡∏∑‡∏≠ <repo_id>/<filename>.pt
        seed=-1,
        remove_silence=True,
        speed=1.0,
        cross_fade_duration=0.15,
        nfe_step=32,
        cfg_strength=2.0,
        sway_sampling_coef=-1.0,
        fix_duration=0.0,
        max_chars=250,
    ):
        # 1. Transliterate English segments into Thai
        translit = eng_to_thai_translit(text)

        # 2. Clean numbers and Thai repeats
        cleaned = process_thai_repeat(replace_numbers_with_thai(translit))

        # 3. Prepare reference audio file
        wav = sample_audio["waveform"].float().contiguous()
        if wav.ndim == 3:
            wav = wav.squeeze()
        elif wav.ndim == 1:
            wav = wav.unsqueeze(0)
        sr = sample_audio["sample_rate"]
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpf:
            sf.write(tmpf.name, wav.cpu().numpy().T, sr)
            ref_path = tmpf.name
        ref_audio, ref_text = preprocess_ref_audio_text(ref_path, sample_text)
        os.unlink(ref_path)

        # 4. Load model config
        cfg_dir = os.path.join(Install.base_path, "src", "f5_tts", "configs")
        for fn in ["F5TTS_Base.yaml", "F5TTS_Base_train.yaml"]:
            p = os.path.join(cfg_dir, fn)
            if os.path.exists(p):
                model_cfg = OmegaConf.load(p).model.arch
                break
        else:
            raise FileNotFoundError("Config file not found")

        # 5. Parse model_path into repo_id + filename
        parts = model_path.strip().split("/")
        if len(parts) < 2:
            raise ValueError(
                "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô <namespace>/<repo_name>/model/<filename>.pt "
                "‡∏´‡∏£‡∏∑‡∏≠ <namespace>/<repo_name>/<filename>.pt"
            )
        repo_id = f"{parts[0]}/{parts[1]}"
        rest = "/".join(parts[2:])  # ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô "model/model_62400.pt" ‡∏´‡∏£‡∏∑‡∏≠ "model_62400.pt"
        filename = os.path.basename(rest)

        # 6. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
        submod_model_dir = os.path.join(
            Install.base_path, "submodules", "F5TTS-on-Pod", "model", "model"
        )
        if os.path.isdir(submod_model_dir):
            mdir = submod_model_dir
        else:
            mdir = os.path.join(Install.base_path, "model")
        os.makedirs(mdir, exist_ok=True)
        local_model_path = os.path.join(mdir, filename)

        # 7. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏≠‡∏á 2 ‡∏Å‡∏£‡∏ì‡∏µ
        if not os.path.exists(local_model_path):
            # ‡∏Å‡∏£‡∏ì‡∏µ A: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå model/<filename>.pt
            relpathA = f"model/{filename}"
            urlA = hf_hub_url(repo_id=repo_id, filename=relpathA)
            try:
                download_with_progress(urlA, local_model_path)
            except Exception:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ó‡∏µ‡πà "model/<filename>.pt" ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á fallback ‡πÑ‡∏õ‡∏ó‡∏µ‡πà "<filename>.pt" root ‡∏Ç‡∏≠‡∏á‡∏£‡∏µ‡πÇ‡∏õ
                relpathB = filename
                urlB = hf_hub_url(repo_id=repo_id, filename=relpathB)
                try:
                    download_with_progress(urlB, local_model_path)
                except Exception as e:
                    raise RuntimeError(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å {repo_id}/{filename} ‡πÑ‡∏î‡πâ: {e}")

        # 8. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° vocab.txt
        submod_vocab_dir = os.path.join(
            Install.base_path, "submodules", "F5TTS-on-Pod", "vocab"
        )
        if os.path.isdir(submod_vocab_dir):
            vdir = submod_vocab_dir
        else:
            vdir = os.path.join(Install.base_path, "vocab")
        os.makedirs(vdir, exist_ok=True)
        vocab_path = os.path.join(vdir, "vocab.txt")

        if not os.path.exists(vocab_path):
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î vocab.txt ‡∏à‡∏≤‡∏Å‡∏£‡∏µ‡πÇ‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            try:
                url_vocab = hf_hub_url(repo_id=repo_id, filename="vocab.txt")
                download_with_progress(url_vocab, vocab_path)
            except Exception as e:
                raise RuntimeError(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î vocab.txt ‡∏à‡∏≤‡∏Å {repo_id} ‡πÑ‡∏î‡πâ: {e}")

        # 9. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• + vocoder ‡∏•‡∏á device
        model = load_model(DiT, model_cfg, local_model_path, vocab_file=vocab_path, mel_spec_type="vocos")
        vocoder = load_vocoder("vocos")
        device = comfy.model_management.get_torch_device()
        model.to(device)
        vocoder.to(device)
        if seed >= 0:
            torch.manual_seed(seed)

        # 10. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° fix_duration Arg
        fd = None if fix_duration == 0.0 else fix_duration

        # 11. Generate audio (‡∏™‡πà‡∏á cleaned ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ chunk_text ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å batch ‡πÄ‡∏≠‡∏á)
        audio_np, sr_out, _ = infer_process(
            ref_audio, ref_text, cleaned,
            model, vocoder=vocoder,
            speed=speed,
            cross_fade_duration=cross_fade_duration,
            nfe_step=nfe_step,
            cfg_strength=cfg_strength,
            sway_sampling_coef=sway_sampling_coef,
            fix_duration=fd,
            set_max_chars=max_chars,
            mel_spec_type="vocos",
            device=device
        )

        # 12. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Tensor
        audio_tensor = torch.from_numpy(audio_np)
        if audio_tensor.ndim == 1:
            audio_tensor = audio_tensor.unsqueeze(0)

        # 13. ‡∏ï‡∏±‡∏î silence ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        if remove_silence:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp2:
                sf.write(tmp2.name, audio_tensor.cpu().numpy().T, sr_out)
                remove_silence_for_generated_wav(tmp2.name)
                audio_tensor, sr_out = torchaudio.load(tmp2.name)
                try:
                    os.unlink(tmp2.name)
                except PermissionError:
                    pass

        return {"waveform": audio_tensor, "sample_rate": sr_out}, cleaned
